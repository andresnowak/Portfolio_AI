{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andres Eduardo Nowak de Anda **A01638430**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Portafolio implementacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMA0401C Aprendizaje e IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliza un framework para entrenar un modelo de aprendizaje profundo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Porque tengo esta competencia?**\n",
    "  - Esta competencia la tengo ya que llegue a utilizar la libreria de keras y tensorflow para poder hacer la creacion de modelos de MLP, CNN\n",
    "  - Hice la transferencia de conocimiento de modelos de deep learning como ResNet usando keras y tensoflow\n",
    "  - Use tensorflow y keras para crear flujos de trabajo para los datos para que los modelos puedan consumirlos.\n",
    "- **Evidencia de trabajo**\n",
    "  - Lineas de codigo utilizada para la importacion de librerias para la tarea de reconocimiento de prendas del conjunto de datos de fashion mnist \n",
    "    - ```python\n",
    "      import pandas as pd\n",
    "      import numpy as np\n",
    "      import tensorflow as tlf\n",
    "      import matplotlib.pyplot as plt\n",
    "      import seaborn as sns\n",
    "      import keras\n",
    "      import tensorflow as tf\n",
    "      \n",
    "      from keras.datasets import fashion_mnist\n",
    "      from tensorflow.keras import models\n",
    "      from tensorflow.keras import Sequential\n",
    "      from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, GlobalAveragePooling2D, GaussianNoise, AveragePooling2D, BatchNormalization\n",
    "      from tensorflow.keras.optimizers import SGD, Adam\n",
    "      from tensorflow.keras import regularizers\n",
    "      from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "  - Lineas de codigo para la creacion de un modelo que utiliza transferencia de conocimiento del modelo ResNet\n",
    "    - ```python\n",
    "        resnet = tf.keras.applications.ResNet50V2(\n",
    "                    include_top=False,\n",
    "                    weights=\"imagenet\",\n",
    "                    input_tensor=None,\n",
    "                    input_shape=shape,\n",
    "                    pooling=None)\n",
    "\n",
    "        for layer in resnet.layers:\n",
    "\t        layer.trainable = False\n",
    "            \n",
    "        model.add(resnet)\n",
    "\n",
    "        model.add(GlobalAveragePooling2D())\n",
    "        model.add(Dense(256, activation='elu'))\n",
    "        model.add(Dense(256, activation='elu'))\n",
    "  - [Modelo MLP de regresion para proyecto de la materia](https://github.com/andresnowak/Hydrology_AI_project/blob/main/models/MLPRegressor_v2.ipynb)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalúa el desempeño del modelo en su aproximación inicial y realiza ajustes para mejorar su desempeño"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Porque tengo esta competencia?**\n",
    "  - Tengo esta competencia ya que llegue a utilizar tecnicas como cross-validation con random search o grid search para encontrar el mejor modelo para usar.\n",
    "  - Tambien llegue a utilizar tecnicas como estar guardando el mejor modelo en cada epoca en base al loss de validacion y la tecnica de early stopping para optimizacion de entrenamiento el modelo asi reducir el tiempo de entreneamiento despues de una cantidad de epocas en el que el modelo no mejor\n",
    "  - Y llegue a a aprender sobre diferentes optimizadores (como Adam y SGD) y diferentes metricas de perdida (como dice loss, focal loss, mse, huber loss), para la creacion de modelos en las tareas y proyectos\n",
    "- **Evidencia de trabajo**\n",
    "  - [Actividad de Deep Learning donde se usa Data augmenting and early stopping](https://github.com/andresnowak/Portfolio_AI/blob/main/activity4_transfer_learning.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utiliza un conjunto de datos reales (no ejemplos de clase), para la creación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Porque tengo esta competencia?**\n",
    "  - Tengo esta competencia ya que use aparte de los conjuntos de datos proporcionados por la clase (ej. El conjunto de datos de la universidad de nebraska), para la creacion de modelos como el modelo para la segmentacion de rios usando el [dataset de Riwa](https://www.kaggle.com/datasets/franzwagner/river-water-segmentation-dataset) o hacer web scrapping para obtener infomracion de articulos de wikipedia para hacer preguntas a un modelo BERT de Q&A para NLP.\n",
    "- **Evidencia de trabajo**\n",
    "  - [Modelo entrenado con el conjunto de datos de Riwa](https://github.com/andresnowak/river_segmentation/blob/main/binary%20segmentation.ipynb)\n",
    "  - [Estudio de los resultados del modelo de segmentacion entrenado en el conjunto de datos de Riwa en kaggle](https://github.com/andresnowak/Hydrology_AI_project/blob/main/dataset_study_v2.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El modelo puede generar predicciones o recomendaciones a través de la consola o una interfaz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Porque tengo esta competencia?**\n",
    "  - Tengo esta competencia ya que para evidencias y tareas llegue a trabajar en la creacion de modelos que permiten hacer predicciones a traves de la interfaz de jupyter en modelos como modelos de prediccion (ej. tarea de prediccion de numeros) y modelos para poder hacer Q&A (ej. Modelo Q&A para preguntas sobre los rios)\n",
    "- **Evidencia de trabajo**\n",
    "  - [Actividad predicción de prendas](https://github.com/andresnowak/Portfolio_AI/blob/main/Activity2-fashion_mnist.ipynb)\n",
    "  - [Modelo para hacer preguntas sobre informacion de los rios](https://github.com/samueldiaz1004/Portafolio-AI/tree/main/Aplicacion%20de%20Lenguaje%20Natural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMA0402C Reconocimiento de patrones, lenguaje natural e IA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puede integrar una interfaz de lenguaje natural  escrito a una aplicación haciendo uso de APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Porque tengo esta competencia?**\n",
    "  - Tengo esta competencia ya que llegue a trabajar en la creacion de un modelo de Q&A utilizando un modelo pre-entrenado BERT para poder hacer preguntas sobre la informacion de rios (el conjunto de datos se obutvo haciendo web-scrapping sobre wikipedia y tambien se obtuvo informacion extra agarrando fragmentos de paginas webs). Y en este proyecto se creo una api para poder hacer las preguntas y obtener de manera facil las respuestas utilizando jupyter\n",
    "- **Evidencia de trabajo**\n",
    "  - [Modelo para hacer preguntas sobre informacion de los rios](https://github.com/samueldiaz1004/Portafolio-AI/tree/main/Aplicacion%20de%20Lenguaje%20Natural)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puede integrar una interfaz de lenguaje natural  en audio o voz a una aplicación haciendo uso de APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No se realizó ninguna actividad de este tipo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analiza un texto con herramientas de NLP para obtener información relevante: análisis de sentimientos, generación de texto, generación de audio, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Porque tengo esta competencia?**\n",
    "  - Tengo esta evidencia ya que llegue a utilziar un modelo pre-entrenado para el analisis de sentimientos de tweets. En donde se comprueba el funcionamiento con el conjunto de datos de los tweets de elon musk\n",
    "- **Evidencia de trabajo**\n",
    "  - [Actividad de analisis de sentimientos](https://github.com/andresnowak/Portfolio_AI/blob/main/nlp.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMA0101C Construcción de modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifica correctamente si el problema a tratar requiere un modelo estocástico o determinista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **¿Porque tengo esta competencia?**\n",
    "  - Tengo esta evidencia ya que que llegue a crear multiples modelos deterministas (ej. CNN, MLP, regression linear, etc.).\n",
    "  - Para nuestro proyecto el modelo que se tenia que utilizar era determinista, ya que los resultados a predecir no son aleatorios, se necesita uan formula para predecir datos que tienen un patron, tienen una logica\n",
    "- **Evidencia de trabajo**\n",
    "  - [Modelo MLP que usa el mes y el ancho del rio para predecir la altura de un rio](https://github.com/andresnowak/Hydrology_AI_project/blob/main/models/models_results/MLPRegressor_Seg_v3_stage_2.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explica claramente las ventajas y desventajas del modelo seleccionado para este problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No aplica** ya que no hubo ni un problema que necesitara el uso de un modelo estocastico y no tendria ni una ventaja usar un modelo estocastico ya que no aplica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3e015569de52eef759f1e1f588a87233645ce0525ddc54b9ca350d557be76967"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
